{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5caeea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2375bfca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(type(x_train), x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c31a3963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visulise the data\n",
    "img1 = x_train[0]\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig1 = plt.figure(figsize=(2,2))\n",
    "plt.imshow(img1)\n",
    "plt.title(y_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1664461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4ec1a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "#format the input data\n",
    "feature_size = img1.shape[0] * img1.shape[1]\n",
    "\n",
    "#reshape 3D to 2D\n",
    "x_train_format = x_train.reshape(x_train.shape[0], feature_size)\n",
    "x_test_format = x_test.reshape(x_test.shape[0], feature_size)\n",
    "print(x_train_format.shape)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f9eca0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.01176471 0.07058824 0.07058824 0.07058824\n",
      " 0.49411765 0.53333333 0.68627451 0.10196078 0.65098039 1.\n",
      " 0.96862745 0.49803922 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.11764706 0.14117647 0.36862745 0.60392157\n",
      " 0.66666667 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.88235294 0.6745098  0.99215686 0.94901961 0.76470588 0.25098039\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.19215686\n",
      " 0.93333333 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.98431373 0.36470588 0.32156863\n",
      " 0.32156863 0.21960784 0.15294118 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.07058824 0.85882353 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.99215686 0.77647059 0.71372549\n",
      " 0.96862745 0.94509804 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.31372549 0.61176471 0.41960784 0.99215686\n",
      " 0.99215686 0.80392157 0.04313725 0.         0.16862745 0.60392157\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.05490196 0.00392157 0.60392157 0.99215686 0.35294118\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.54509804 0.99215686 0.74509804 0.00784314 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.04313725\n",
      " 0.74509804 0.99215686 0.2745098  0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.1372549  0.94509804\n",
      " 0.88235294 0.62745098 0.42352941 0.00392157 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.31764706 0.94117647 0.99215686\n",
      " 0.99215686 0.46666667 0.09803922 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.17647059 0.72941176 0.99215686 0.99215686\n",
      " 0.58823529 0.10588235 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.0627451  0.36470588 0.98823529 0.99215686 0.73333333\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.97647059 0.99215686 0.97647059 0.25098039 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.18039216 0.50980392 0.71764706 0.99215686\n",
      " 0.99215686 0.81176471 0.00784314 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.15294118 0.58039216\n",
      " 0.89803922 0.99215686 0.99215686 0.99215686 0.98039216 0.71372549\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.09411765 0.44705882 0.86666667 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.78823529 0.30588235 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.09019608 0.25882353 0.83529412 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.77647059 0.31764706 0.00784314\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.07058824 0.67058824\n",
      " 0.85882353 0.99215686 0.99215686 0.99215686 0.99215686 0.76470588\n",
      " 0.31372549 0.03529412 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.21568627 0.6745098  0.88627451 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.95686275 0.52156863 0.04313725 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.53333333 0.99215686\n",
      " 0.99215686 0.99215686 0.83137255 0.52941176 0.51764706 0.0627451\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "#normalize data\n",
    "x_train_normal = x_train_format/255\n",
    "x_test_normal = x_test_format/255\n",
    "\n",
    "print(x_train_normal[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9287b9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 ... 5 6 8]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#format the output\n",
    "from keras.utils import to_categorical\n",
    "y_train_format = to_categorical(y_train)\n",
    "y_test_format = to_categorical(y_test)\n",
    "\n",
    "print(y_train)\n",
    "print(y_train_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd5154af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 392)               307720    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 392)               154056    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                3930      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 465,706\n",
      "Trainable params: 465,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#setup the model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "mlp = Sequential()\n",
    "mlp.add(Dense(units=392, activation='sigmoid', input_dim=feature_size))\n",
    "mlp.add(Dense(units=392, activation='sigmoid',))\n",
    "mlp.add(Dense(units=10, activation='softmax'))\n",
    "mlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e825426",
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure the model\n",
    "mlp.compile(loss='categorical_crossentropy', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8788f581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   1/1875 [..............................] - ETA: 5:47 - loss: 2.4140"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-29 16:49:59.255030: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3407\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1436\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0921\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0660\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0470\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0358\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0270\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0197\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0176\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0130\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x315c635e0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(x_train_normal, y_train_format, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "81770586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 1s 573us/step\n",
      "[5 0 4 ... 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "#evaluate the model\n",
    "import numpy as np\n",
    "y_train_predict = np.argmax(mlp.predict(x_train_normal),axis=1)\n",
    "print(y_train_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e4730cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9957333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_train_predict)\n",
    "print(accuracy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "95b0b766",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'predicte'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_test_prect \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[43mmlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredicte\u001b[49m(x_test_normal), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      2\u001b[0m accuracy_test \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_test_prect)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(accuracy_test)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predicte'"
     ]
    }
   ],
   "source": [
    "y_test_prect = np.argmax(mlp.predict(x_test_normal), axis=1)\n",
    "accuracy_test = accuracy_score(y_test, y_test_prect)\n",
    "print(accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac47c25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199fa156",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
